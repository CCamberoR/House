{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d7105f1-304b-47ce-8b3b-eccf0bc79e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import faiss\n",
    "\n",
    "\n",
    "torch.backends.cudnn.benchmark = True  # Improves performance when input size is constant\n",
    "\n",
    "# Function to load documents from a directory containing Parquet files\n",
    "def load_documents_from_parquet(directory, title_column=\"title\", content_column=\"content\"):\n",
    "    documents = {}\n",
    "    doc_id = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".parquet\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            try:\n",
    "                df = pd.read_parquet(filepath)\n",
    "                if title_column not in df.columns or content_column not in df.columns:\n",
    "                    raise ValueError(f\"Columns '{title_column}' or '{content_column}' not found in Parquet file: {filename}\")\n",
    "                for index, row in df.iterrows():\n",
    "                    # Combine title and content for each document\n",
    "                    combined_text = f\"{row[title_column]} {row[content_column]}\"\n",
    "                    documents[doc_id] = combined_text\n",
    "                    doc_id += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading Parquet file {filename}: {e}\")\n",
    "    return documents\n",
    "\n",
    "class MedRAG:\n",
    "    def __init__(self, llm_name, rag, retriever_name, corpus_dir, title_column=\"title\", content_column=\"content\"):\n",
    "        self.llm_name = llm_name\n",
    "        self.rag = rag\n",
    "        self.retriever_name = retriever_name\n",
    "        self.corpus_dir = corpus_dir\n",
    "        self.title_column = title_column\n",
    "        self.content_column = content_column\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(llm_name)\n",
    "        self.model = AutoModel.from_pretrained(llm_name)\n",
    "\n",
    "        # Use GPU if available\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # Load the corpus from Parquet files\n",
    "        self.corpus = load_documents_from_parquet(corpus_dir, title_column=self.title_column, content_column=self.content_column)\n",
    "        if not self.corpus:\n",
    "            raise ValueError(f\"No documents found in directory: {corpus_dir} or columns '{self.title_column}'/'{self.content_column}' are missing\")\n",
    "        print(f\"Loaded {len(self.corpus)} documents from {corpus_dir}\")\n",
    "\n",
    "        # Compute embeddings in batches and build FAISS index\n",
    "        self.embedding_dim = self.model.config.hidden_size\n",
    "        self.index = faiss.IndexFlatIP(self.embedding_dim)  # Index for cosine similarity (Inner Product)\n",
    "\n",
    "        batch_size = 16  # Adjust batch size for optimal performance on RTX 4070\n",
    "        self.corpus_embeddings = self.compute_embeddings_batched(list(self.corpus.values()), batch_size)\n",
    "        self.index.add(self.corpus_embeddings.numpy())\n",
    "\n",
    "    def compute_embeddings_batched(self, texts, batch_size):\n",
    "        all_embeddings = []\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i + batch_size]\n",
    "            inputs = self.tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "            inputs = {key: value.to(self.device) for key, value in inputs.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "            embeddings = outputs.last_hidden_state[:, 0, :].cpu()\n",
    "            all_embeddings.append(embeddings)\n",
    "        return torch.cat(all_embeddings, dim=0)\n",
    "\n",
    "    def answer(self, question, k):\n",
    "        if self.rag:\n",
    "            snippets, scores, doc_ids = self.retrieve(question, k)\n",
    "        else:\n",
    "            snippets, scores, doc_ids = [], [], []\n",
    "\n",
    "        # Generate answer based on retrieved snippets\n",
    "        selected_answer = self.select_answer(question, snippets)  # No options passed\n",
    "\n",
    "        return selected_answer, snippets, scores, doc_ids\n",
    "\n",
    "    def retrieve(self, question, k):\n",
    "        # Compute the question embedding\n",
    "        question_embedding = self.compute_embeddings_batched([question], batch_size=1)  # Use the batched function\n",
    "        question_embedding = question_embedding[0].unsqueeze(0) #.numpy()\n",
    "\n",
    "        # Search the FAISS index\n",
    "        D, I = self.index.search(question_embedding.numpy(), k)\n",
    "\n",
    "        # Retrieve snippets and scores\n",
    "        doc_ids = I[0].tolist()\n",
    "        snippets = [list(self.corpus.values())[i] for i in doc_ids]\n",
    "        scores = D[0].tolist()\n",
    "\n",
    "        return snippets, scores, doc_ids\n",
    "\n",
    "    def select_answer(self, question, snippets):\n",
    "        # Combine question and snippets for context\n",
    "        context = f\"Question: {question}\\n\"\n",
    "        if snippets:\n",
    "            context += \"\\nContext:\\n\" + \"\\n\".join(snippets)\n",
    "        context += \"\\nAnswer:\"\n",
    "\n",
    "        # Tokenize and encode the context\n",
    "        inputs = self.tokenizer(context, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "\n",
    "        # Generate the answer using the model\n",
    "        with torch.no_grad():\n",
    "            # Use model's generate method with appropriate parameters\n",
    "            outputs = self.model.generate(\n",
    "                input_ids=inputs[\"input_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"],\n",
    "                max_length=100,  # Adjust as needed\n",
    "                do_sample=True,\n",
    "                top_k=50,  # Adjust as needed\n",
    "                top_p=0.95,  # Adjust as needed\n",
    "            )\n",
    "\n",
    "        # Decode the generated answer\n",
    "        answer = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0ab9311-007d-42e1-8760-ba8036922ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89efb306ad5c4e04953706965b77f582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6884df2e969744c4ade6ed6b44c1cc67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d320c7603234428184fbc01f14a4f593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "496a4c66557041d09a2130502f9311eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90dd0f064fa4401783190c18284401ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 213527 documents from data_RAG\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 8\u001b[0m\n\u001b[1;32m      2\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA lesion causing compression of the facial nerve at the stylomastoid foramen will cause ipsilateral\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# --- IMPORTANT:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Ensure your 'data_RAG' directory exists and contains your Parquet files.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# ---\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m medrag \u001b[38;5;241m=\u001b[39m \u001b[43mMedRAG\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfacebook/bart-base\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretriever_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFaissRetriever\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Indicate we're using FAISS\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcorpus_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata_RAG\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtitle_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtitle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcontent_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m answer, snippets, scores, doc_ids \u001b[38;5;241m=\u001b[39m medrag\u001b[38;5;241m.\u001b[39manswer(question\u001b[38;5;241m=\u001b[39mquestion, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelected Answer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manswer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[21], line 57\u001b[0m, in \u001b[0;36mMedRAG.__init__\u001b[0;34m(self, llm_name, rag, retriever_name, corpus_dir, title_column, content_column)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m faiss\u001b[38;5;241m.\u001b[39mIndexFlatIP(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_dim)  \u001b[38;5;66;03m# Index for cosine similarity (Inner Product)\u001b[39;00m\n\u001b[1;32m     56\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m  \u001b[38;5;66;03m# Adjust batch size for optimal performance on RTX 4070\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_embeddings_batched\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_embeddings\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "Cell \u001b[0;32mIn[21], line 68\u001b[0m, in \u001b[0;36mMedRAG.compute_embeddings_batched\u001b[0;34m(self, texts, batch_size)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     67\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m---> 68\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_hidden_state\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     all_embeddings\u001b[38;5;241m.\u001b[39mappend(embeddings)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(all_embeddings, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- Example Usage (Assuming data_RAG is set up) ---\n",
    "question = \"A lesion causing compression of the facial nerve at the stylomastoid foramen will cause ipsilateral\"\n",
    "\n",
    "# --- IMPORTANT:\n",
    "# Ensure your 'data_RAG' directory exists and contains your Parquet files.\n",
    "# ---\n",
    "\n",
    "medrag = MedRAG(llm_name=\"facebook/bart-base\",\n",
    "                rag=True,\n",
    "                retriever_name=\"FaissRetriever\",  # Indicate we're using FAISS\n",
    "                corpus_dir=\"data_RAG\",\n",
    "                title_column=\"title\",\n",
    "                content_column=\"content\")\n",
    "\n",
    "answer, snippets, scores, doc_ids = medrag.answer(question=question, k=3)\n",
    "\n",
    "print(f\"Selected Answer: {answer}\")\n",
    "print(f\"Retrieved Snippets: {snippets}\")\n",
    "print(f\"Retrieval Scores: {scores}\")\n",
    "print(f\"Retrieved Doc IDs: {doc_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "091a7cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to medrag_data_saved_embeddings_and_faiss_index/embeddings.npy\n",
      "FAISS index saved to medrag_data_saved_embeddings_and_faiss_index/faiss.index\n",
      "Corpus mapping saved to medrag_data_saved_embeddings_and_faiss_index/corpus.pkl\n",
      "All MedRAG data saved to medrag_data_saved_embeddings_and_faiss_index\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# ... (Your MedRAG class and other code) ...\n",
    "\n",
    "# --- Saving Embeddings, FAISS Index, and Corpus ---\n",
    "\n",
    "def save_medrag_data(medrag, save_dir):\n",
    "    \"\"\"Saves the MedRAG model's embeddings, FAISS index, and corpus mapping.\n",
    "\n",
    "    Args:\n",
    "        medrag: The MedRAG instance.\n",
    "        save_dir: The directory to save the data to.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # 1. Save Embeddings (as a NumPy array)\n",
    "    embeddings_file = os.path.join(save_dir, \"embeddings.npy\")\n",
    "    np.save(embeddings_file, medrag.corpus_embeddings.numpy())\n",
    "    print(f\"Embeddings saved to {embeddings_file}\")\n",
    "\n",
    "    # 2. Save FAISS Index\n",
    "    index_file = os.path.join(save_dir, \"faiss.index\")\n",
    "    faiss.write_index(medrag.index, index_file)\n",
    "    print(f\"FAISS index saved to {index_file}\")\n",
    "\n",
    "    # 3. Save Corpus (using Pickle)\n",
    "    corpus_file = os.path.join(save_dir, \"corpus.pkl\")\n",
    "    with open(corpus_file, \"wb\") as f:\n",
    "        pickle.dump(medrag.corpus, f)\n",
    "    print(f\"Corpus mapping saved to {corpus_file}\")\n",
    "\n",
    "    print(f\"All MedRAG data saved to {save_dir}\")\n",
    "\n",
    "# --- Example of Saving ---\n",
    "\n",
    "# Assuming you have initialized your MedRAG instance as 'medrag'\n",
    "save_dir = \"medrag_data_saved_embeddings_and_faiss_index\"  # Choose a directory to save your data\n",
    "save_medrag_data(medrag, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f83de7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Answer: A\n",
      "Retrieved Snippets: ['International predictive testing for NCLEX-RN. Rewards and risks. The United States still relies heavily on foreign nurses, and that means heavy reliance on them passing the state board examinations. Can we predict successful performance? Wells tells us the risks and rewards.', \"Credit where credit's due. How to borrow money effectively. Neither a borrower or a lender be, says the old proverb. However, used effectively, credit can help you to make the most of your money - so long as you are careful!\", 'Missouri leads the nation: and that needs to change. In Missouri, legislation to control tobacco use severely lags behind other states who have beaten us to the punch by passing such laws. It is time to make some changes, and you can help.']\n",
      "Retrieval Scores: [217.67137145996094, 216.8662109375, 216.736083984375]\n",
      "Retrieved Doc IDs: [91684, 130427, 174199]\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage (Assuming data_RAG is set up) ---\n",
    "question = \"I have a question about lung cancer. What are the risk factors?\"\n",
    "\n",
    "# --- IMPORTANT:\n",
    "# Ensure your 'data_RAG' directory exists and contains your Parquet files.\n",
    "# ---\n",
    "\n",
    "answer, snippets, scores, doc_ids = medrag.answer(question=question, k=3)\n",
    "\n",
    "print(f\"Selected Answer: {answer}\")\n",
    "print(f\"Retrieved Snippets: {snippets}\")\n",
    "print(f\"Retrieval Scores: {scores}\")\n",
    "print(f\"Retrieved Doc IDs: {doc_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4784017e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Answer: A\n",
      "Retrieved Snippets: ['Missouri leads the nation: and that needs to change. In Missouri, legislation to control tobacco use severely lags behind other states who have beaten us to the punch by passing such laws. It is time to make some changes, and you can help.', \"Boiling snow in north Romania. One day Andy Beazley was a busy dentist, the next he found himself setting off for a week in a Romanian children's hospital, loaded to the brim with blankets, bedding and toys. When he goes back in March, he hopes to take a couple of Portakabins and some drainage equipment. What did he discover while he was there and how healthy are Romanian teeth?\", 'Res ipsa loquitur--putting the health care provider on the hot seat. Just when you thought you knew all of the fine points of malpractice, McMullen describes a new way of getting sued. Fortunately, she also suggests ways to avoid it.']\n",
      "Retrieval Scores: [217.4948272705078, 217.46316528320312, 217.03416442871094]\n",
      "Retrieved Doc IDs: [174199, 134969, 40725]\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage (Assuming data_RAG is set up) ---\n",
    "question = \"My knees hurt when I run. What could be the cause?\"\n",
    "\n",
    "# --- IMPORTANT:\n",
    "# Ensure your 'data_RAG' directory exists and contains your Parquet files.\n",
    "# ---\n",
    "\n",
    "answer, snippets, scores, doc_ids = medrag.answer(question=question, k=3)\n",
    "\n",
    "print(f\"Selected Answer: {answer}\")\n",
    "print(f\"Retrieved Snippets: {snippets}\")\n",
    "print(f\"Retrieval Scores: {scores}\")\n",
    "print(f\"Retrieved Doc IDs: {doc_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1599f0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Answer: B\n",
      "Retrieved Snippets: [\"Boiling snow in north Romania. One day Andy Beazley was a busy dentist, the next he found himself setting off for a week in a Romanian children's hospital, loaded to the brim with blankets, bedding and toys. When he goes back in March, he hopes to take a couple of Portakabins and some drainage equipment. What did he discover while he was there and how healthy are Romanian teeth?\", \"Credit where credit's due. How to borrow money effectively. Neither a borrower or a lender be, says the old proverb. However, used effectively, credit can help you to make the most of your money - so long as you are careful!\", 'Missouri leads the nation: and that needs to change. In Missouri, legislation to control tobacco use severely lags behind other states who have beaten us to the punch by passing such laws. It is time to make some changes, and you can help.']\n",
      "Retrieval Scores: [220.4746551513672, 220.32826232910156, 219.60935974121094]\n",
      "Retrieved Doc IDs: [134969, 130427, 174199]\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage (Assuming data_RAG is set up) ---\n",
    "question = \"I have a cold. What could be the cause?\"\n",
    "\n",
    "# --- IMPORTANT:\n",
    "# Ensure your 'data_RAG' directory exists and contains your Parquet files.\n",
    "# ---\n",
    "\n",
    "answer, snippets, scores, doc_ids = medrag.answer(question=question, k=3)\n",
    "\n",
    "print(f\"Selected Answer: {answer}\")\n",
    "print(f\"Retrieved Snippets: {snippets}\")\n",
    "print(f\"Retrieval Scores: {scores}\")\n",
    "print(f\"Retrieved Doc IDs: {doc_ids}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
